{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c2dd92",
   "metadata": {},
   "source": [
    "## Part 1: Conceptual Warm-Up (No Coding)\n",
    "\n",
    "**Goal:** Ensure students understand the foundational concepts through explanation and derivation.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "#### 1. Short Answer Questions\n",
    "\n",
    "a) Derive the gradient update rule for the weight(s) for a single neuron with one input feature (i.e.,  \n",
    "field, or attribute) and the sigmoid activation function:\n",
    "\n",
    "$\\sigma(x) = \\frac{1}{1 + e^{-x}}$\n",
    "\n",
    "b) Explain the role of the activation function in a neural network. Please guess without searching  \n",
    "textbook/the Internet.\n",
    "\n",
    "c) What is overfitting, and how can it be mitigated? List a couple of techniques to reduce overfitting.\n",
    "\n",
    "d) Can you guess what might be an underfitting problem? How can that be mitigated? List a couple of  \n",
    "techniques to reduce underfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d2982f",
   "metadata": {},
   "source": [
    "#### 2. Math Problem\n",
    "\n",
    "a) For the following small binary classification dataset (4 samples each with two input features  \n",
    "$(x_1, x_2)$ and one target feature $(y)$):  \n",
    "\n",
    "Compute the forward passes and the gradients manually for a neural network with 1 hidden layer  \n",
    "(with 2 neurons) and 1 output neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9daf523",
   "metadata": {},
   "source": [
    "## Part 2: Build a Neural Network from Scratch (Coding)\n",
    "\n",
    "**Goal:** Students implement a simple neural network without relying on deep learning libraries like TensorFlow or PyTorch.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "#### 3. Implement a neural network with:\n",
    "\n",
    "a) 1 input layer, 1 hidden layer (with 2 neurons), and 1 output layer.  \n",
    "\n",
    "b) Use a non-linear activation function (e.g., sigmoid, ReLU, tanh, etc.) for each of the neurons.  \n",
    "\n",
    "c) Do not forget to introduce the bias inputs for the two neural layers (i.e., hidden layer and output layer).  \n",
    "\n",
    "d) Consider **mean squared error (MSE)** as the loss/error function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff7a35",
   "metadata": {},
   "source": [
    "#### 4. Train it on the dataset:\n",
    "\n",
    "- Small dataset of 4 samples (denoted by rows in *Fig. 1*).  \n",
    "- Each sample has two input features $(x_1, x_2)$ and one target feature $(y)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba83866",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "- Implement **forward propagation** and the **backpropagation algorithm** manually.  \n",
    "  (Refer to the boilerplate code for placeholders where your implementations should go.)  \n",
    "- Train the network for a fixed number of **epochs (10,000)** and plot the **loss over time**.  \n",
    "\n",
    "### Specific Guidelines\n",
    "\n",
    "- Do **not** use any pre-built neural network libraries. Only use libraries for basic operations (e.g., NumPy).  \n",
    "- Write **detailed comments** in your code to explain each step of your implementation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e555ee",
   "metadata": {},
   "source": [
    "## Part 3: Experimentation and Analysis\n",
    "\n",
    "**Goal:** Encourage critical thinking.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "#### 5. Hyperparameter Tuning\n",
    "\n",
    "- Experiment with different **learning rates** and **hidden layer sizes**.  \n",
    "- Analyze how these changes impact the **convergence** and **performance** of your model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0f849",
   "metadata": {},
   "source": [
    "#### 6. Visualization\n",
    "\n",
    "- Plot **decision boundaries** after training your model.  \n",
    "- Provide insights into how the model separates the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d5484",
   "metadata": {},
   "source": [
    "## Part 4: Reflective Questions\n",
    "\n",
    "**Goal:** Make students reflect on the learning process.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "#### 7. Backpropagation Challenges\n",
    "- What challenges did you face in implementing backpropagation?  \n",
    "- How did you overcome them?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b3e0d3",
   "metadata": {},
   "source": [
    "#### 8. Debugging\n",
    "- Explain the importance of **debugging** in neural network training.  \n",
    "- Provide one strategy that helped you debug effectively.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d913c",
   "metadata": {},
   "source": [
    "#### 9. Activation Function Choice\n",
    "- Discuss how the training process would change if you used a different activation function  \n",
    "  (e.g., tanh instead of ReLU, or vice versa).\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
